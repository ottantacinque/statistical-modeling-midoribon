cDay
barplot(cDay)
p5<-rep(1/12,12)
chisq.test(cDay,p=p5)
chisq.test(cDay)
#[2]
winter2<-c(cDay[c(1:4,10:12)])
summer2<-c(cDay[c(5:9)])
boxplot(winter2,summer2,names=c("winter","summer"))
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="greater")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="greater")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
summer2
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
chisq.test(Obs,p=P)
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
chisq.test(x=experiment,p=theoretical)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
chisq.test(x=experiment,p=theoretical)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
Ndata<-rnorm(1000,mean=5,sd=3)  #Normal random number
Udata<-runif(1000,min=0,max=1)  #Uniform random number
#--Shapiro Wilk test
shapiro.test(Ndata)
#--Shapiro Wilk test
shapiro.test(Ndata)
shapiro.test(Udata)
#--QQ plot --------------
qqplot(qnorm(ppoints(1000)),Ndata)
qqplot(qnorm(ppoints(1000)),Udata)
#--Shapiro Wilk test
shapiro.test(Ndata)
shapiro.test(Udata)
#--QQ plot --------------
qqplot(qnorm(ppoints(1000)),Ndata)
#--ks test --------------
ks.test(Ndata,"pnorm", mean=mean(Ndata),sd(Ndata))
ks.test(Udata,"pnorm", mean=mean(Udata),sd(Udata))
?ks.test
ks.test(Ndata,"punif")
ks.test(Udata,"punif")
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
chisq.test(x=experiment,p=theoretical)
#Quiz42
#Quiz42
#ア:帰無仮説
#Quiz42
#ア:帰無仮説
#イ:帰無仮説
#データの読み込み
load("data.Rata")
data
length(data)
# dataの要約
summary(data)
# 度数分布を得る
table(data)
# ヒストグラム
hist(data, breaks = seq(-0.5, 9.5, 1))
# 標本分散
var(data)
# 標本標準偏差
sd(data)
sqrt(var(data))
# 平均3.56のポアソン分布を図示してみる。
y <- 0:9
prob <- dpois(y, lambda = 3.56)
plot(y, prob, type = "b", lty = 2)
# 対数尤度LogL(lambda)とlambdaの関係を調べる
logL <- function(m) sum(dpois(data, m, log=TRUE))
y <- 0:9
prob <- dpois(y, lambda = 3.56)
plot(y, prob, type = "b", lty = 2)
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "b", lty = 2)
# 平均3.56のポアソン分布を図示してみる。
y <- 0:9
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "b", lty = 2)
plot(y, prob, type = "l", lty = 2)
plot(y, prob, type = "l", lty = 3)
#データの読み込み
load("data.Rata")
ls
cd
ls
#データの読み込み
load("data.Rata")
data
length(data)
data
length(data)
#データの読み込み
load("data.Rata")
data
length(data)
#データの読み込み
load("data.Rata")
data
length(data)
load("~/Desktop/統計モデリング/.RData")
View(d)
# dataの要約
summary(data)
# 度数分布を得る
table(data)
# ヒストグラム
hist(data, breaks = seq(-0.5, 9.5, 1))
# 標本分散
var(data)
# 標本標準偏差
sd(data)
sqrt(var(data))
# 平均3.56のポアソン分布を図示してみる。
y <- 0:9
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "l", lty = 3)
# 対数尤度LogL(lambda)とlambdaの関係を調べる
logL <- function(m) sum(dpois(data, m, log=TRUE))
lambda <- seq(2, 5, 0.1)
plot(lambda, sapply(lambda, logL), type= "l")
View(d)
data <- c(2, 4, 6, 4, 5, 2, 3, 1, 2, 0,
4, 3, 3, 3, 3, 4, 2, 7, 2, 4,
3, 3, 3, 4, 3, 7, 5, 3, 1, 7,
6, 4, 6, 5, 2, 4, 7, 2, 2, 6,
2, 4, 5, 4, 5, 1, 3, 2, 3)
data
length(data)
# dataの要約
summary(data)
# 度数分布を得る
table(data)
y <- 0:9
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "b", lty = 3)
y <- 0:9
prob <- dpois(y, lambda = 6)
plot(y, prob, type = "b", lty = 3)
logL <- function(m) sum(dpois(data, m, log=TRUE))
lambda <- seq(2, 5, 0.1)
plot(lambda, sapply(lambda, logL), type= "l")
#データの読み込み
load("data.Rata")
data <- read.csv("./../data/my_data.csv")
data <- read.csv("./../data/data.csv")
data <- read.csv("/../data/data.csv")
getwd()
getwd()
cd()
cd
ls
#データの読み込み
getwd()
#データの読み込み
getwd()
data <- read.csv("/../data/data.csv")
F1<-100
F2<-4
N<-10000
FV1<-rchisq(N,df=F1)/F1
FV2<-rchisq(N,df=F2)/F2
Frand<-FV1/FV2
ff<-Frand[Frand<10]
#[1]
hist(ff,breaks=seq(0,10,0.1),freq=FALSE)
curve(df(x,df1=F1,df2=F2),from=0,to=10,add=T,col="red")
#[2]
prob<-pf(ff,df1=F1,df2=F2)
hist(prob,breaks=seq(0,1,0.05))
#[1]
hist(ff,breaks=seq(0,10,0.1),freq=FALSE)
curve(df(x,df1=F1,df2=F2),from=0,to=10,add=T,col="red")
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
head(df)
labeldata<-substring(rownames(df),1,2)
#---------------------------------------------------------
#df<-scale(df)
dataNew<-data.frame(labeldata,df)
dim(dataNew)
sc<-3    #X variables 2-16
dim(dataNew)
#---------------------------------------------------------
#df<-scale(df)
dataNew<-data.frame(labeldata,df)
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
exdata<-c(210,417,136,131,30,435,91,129,
49, 35, 26,  9,26, 12, 9,  7,
96, 85, 42, 22,15, 23,21, 43)
grp<-c("G","G","G","G","G","G","G","G",
"C","C","C","C","C","C","C","C",
"F","F","F","F", "F","F","F","F")
summary(aov(exdata~grp))
#boxplot
grpdata<-tapply(exdata,grp,list)
boxplot(grpdata)
summary(aov(exdata~grp))
grpvar <- tapply(exdata,grp,var)
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
1-pf(Fdata,df1=2,df2=21)
#========================================
summary(aov(exdata~grp))
grpvar <- tapply(exdata,grp,var)
VE <- sum(grapvar * 8) / 21
#========================================
summary(aov(exdata~grp))
grpvar <- tapply(exdata,grp,var)
VE <- sum(grpvar * 8) / 21
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
VA <-  8 * sum((grpmean-allmean)^2) / 2
# fvalue
Fdata = VA/VE
1-pf(Fdata,df1=2,df2=21)
summary(aov(exdata~grp))
1-pf(Fdata,df1=2,df2=21)
# fvalue
VA/VE
1-pf(Fdata,df1=2,df2=21)
VA <-  21 * sum((grpmean-allmean)^2) / 2
# fvalue
VA/VE
1-pf(Fdata,df1=2,df2=21)
VE <- sum(grpvar * 7) / 21
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
VA <-  8 * sum((grpmean-allmean)^2) / 2
# fvalue
VA/VE
1-pf(Fdata,df1=2,df2=21)
# fvalue
Fdata = VA/VE
1-pf(Fdata,df1=2,df2=21)
# 7.1 例題；GLMでは説明出来ないカウントデータ
d <- read.csv("data7.csv")
setwd("~/Desktop/statistical-modeling-midoribon/code")
# 7.1 例題；GLMでは説明出来ないカウントデータ
d <- read.csv("data7.csv")
summary(d)
# プロットの作成
plot(d$x, d$y)
# プロットの作成
plot(jitter(d$x), jitter(d$y))
# プロットの作成
library(ggplot2)
g <- ggplot(data, aes(x = x, y = y)) #データの指定
g <- g + geom_jitter(height=0, width =0.1)
install.packages("ggplot")
install.packages("tidyverse")
# プロットの作成
library(ggplot2)
g <- ggplot(data, aes(x = x, y = y)) #データの指定
g <- g + geom_jitter(height=0, width =0.1)
g <- ggplot(data, aes(x = d$x, y = d$y)) #データの指定
d$x
d$y
g <- ggplot(data=d, aes(x = d$x, y = d$y)) #データの指定
g <- g + geom_jitter(height=0, width =0.1)
plot(g)
theme_bw()
g <- ggplot(data=d, aes(x = d$x, y = d$y)) #データの指定
g <- g + geom_jitter(height=0, width =0.1)
theme_bw()
plot(g)
g <- g + geom_jitter(height=0, width =0.2)
theme_bw()
plot(g)
# プロットの作成
plot(jitter(d$x), d$y)
# プロットの作成
plot(jitter(d$x), d$y)
# プロットの作成
plot(jitter(d$x,0.1), d$y)
# プロットの作成
plot(jitter(d$x,0.5), d$y)
summary(d)
# GLMを当てはめてみる。
glm(cbind(y, N - y) ~ x, data = d, family = binomial)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
summary$x
summary.factor()
test <- model_parameters(fit)
model_parameters(fit)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
model_parameters(fit)
coef(fit)
coef(fit).x
coef(fit)$x
coef(fit)[0]
coef(fit)[1]
coef(fit)[1][1]
coef(fit)[1][1][1]
coef(fit)[2]
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-1.148745 + 0.5103806  * x)))
x <- seq(2 ,6, 0.1)
plot(x, logistic(x), type = "l")
qbinom(0.5, 10, 0.5)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-1.148745 + 0.5103806  * x)))
mean_binom <-  function(x) qbinom(x, 8, 0.5)
x <- seq(2 ,6, 0.1)
plot(x, mean_binom(logistic(x)), type = "l")
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-1.148745 + 0.5103806  * x)))
x <- seq(2 ,6, 0.1)
plot(x, mean_binom(logistic(x))*8, type = "l")
plot(x, logistic(x)*8, type = "l")
d <- read.csv("data4a.csv")
d$f <- as.factor(d$f)
# 各列のまとめを表示する
summary(d)
# 図示してみる
plot(d$x, d$y, pch=c(21,19)[d$f])
# 6.4 ロジスティク回帰とロジットリンク関数
#ロジスティク関数を作図してみる
logistic <- function(z) 1 / (1 + exp(-z))
z <- seq(-6 ,6, 0.1)
plot(z, logistic(z), type= "l")
# ロジスティック回帰のパラメーター推定
# c bind(y, N-y) のyは生存数, N-yは死んだ数
glm(cbind(y, N - y) ~ x + f, data = d, family = binomial)
# 結果を元に図示してみる
logistic <- function(x) 1 / (1 + exp(- (-19.5 + 1.95 * x)))
logistic2 <- function(x) 1 / (1 + exp(- (-19.5 + 1.95 * x + 2.022)))
x <- seq(7 ,12, 0.1)
plot(x, logistic(x), type = "l")
plot(x, logistic2(x), type = "l")
plot(x, logistic(x)*8, type = "l")
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-1.148745 + 0.5103806  * x)))
x <- seq(2 ,6, 0.1)
plot(x, logistic(x)*8, type = "l")
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
d <- read.csv("data7.csv")
summary(d)
# プロットの作成
plot(jitter(d$x,0.5), d$y)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-13.148745 + 0.5103806  * x)))
x <- seq(2 ,6, 0.1)
plot(x, logistic(x)*8, type = "l")
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-2.1487 + 0.5104 * x)))
x <- seq(2 ,6, 0.1)
plot(x, mean_binom(logistic(x))*8, type = "l")
plot(x,logistic(x)*8, type = "l")
points(x,logistic(x)*8, type = "l")
points(x,logistic(x)*8, type = "l")
points(jitter(d$x,0.5), d$y)
points(jitter(d$x,0.5), d$y)
points(x,logistic(x)*8, type = "l")
points(jitter(d$x,0.5), d$y)
# プロットの作成
plot(jitter(d$x,0.5), d$y)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-2.1487 + 0.5104 * x)))
x <- seq(2 ,6, 0.1)
points(jitter(d$x,0.5), d$y)
points(x,logistic(x)*8, type = "l")
plot(jitter(d$x,0.5), d$y)
points(x,logistic(x)*8, type = "l")
# x=4での種子の生存数をプロットしてみる
d_4 <- d[d$x==4]
# x=4での種子の生存数をプロットしてみる
d_4 <- d[d$x=4]
# x=4での種子の生存数をプロットしてみる
d_4 <- d[d$x=4,]
# x=4での種子の生存数をプロットしてみる
d_4 <- d[d$x==4,]
View(d_4)
hist(d_4$y)
# 7.2 か分散と個体差
d4 <- d[d$x==4,]
table(d4$y)
# このデータの平均と分散を調べる
c(mean(d4$9, var(d4$y)))
# このデータの平均と分散を調べる
c(mean(d4$x, var(d4$y))
# このデータの平均と分散を調べる
c(mean(d4$x), var(d4$y))
# このデータの平均と分散を調べる
c(mean(d4$x), var(d4$y))
# x=4での種子の生存数をプロットしてみる
hist(d_4$y)
# 7.4 一般化線形混合モデルの最尤推定
# Rを使ってGLMMのパラメーターを推定する。
fit = glmmML(cbind(y, N-y)~x, data=d, family=binomial, +cluster=id)
# 7.4 一般化線形混合モデルの最尤推定
# Rを使ってGLMMのパラメーターを推定する。
glmmML(cbind(y, N-y)~x, data=d, family=binomial, +cluster=id)
# 7.4 一般化線形混合モデルの最尤推定
# Rを使ってGLMMのパラメーターを推定する。
glmmML(cbind(y, N-y)~x, data=d, family=binomial)
install.packages("glmmML")
# 7.4 一般化線形混合モデルの最尤推定
# Rを使ってGLMMのパラメーターを推定する。
glmmML(cbind(y, N-y)~x, data=d, family=binomial)
# 7.4 一般化線形混合モデルの最尤推定
# Rを使ってGLMMのパラメーターを推定する。
library(glmmML)
glmmML(cbind(y, N-y)~x, data=d, family=binomial)
# 7.1 例題；GLMでは説明出来ないカウントデータ
d <- read.csv("data7.csv")
summary(d)
# プロットの作成
plot(jitter(d$x,0.5), d$y)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-2.1487 + 0.5104 * x)))
x <- seq(2 ,6, 0.1)
plot(jitter(d$x,0.5), d$y)
points(x,logistic(x)*8, type = "l")
# 7.2 過分散と個体差
d4 <- d[d$x==4,]
# 生存数がy_i子であった個体を数える。
table(d4$y)
# このデータの平均と分散を調べる
c(mean(d4$x), var(d4$y))
# x=4での種子の生存数をプロットしてみる
hist(d_4$y)
# 7.4 一般化線形混合モデルの最尤推定
# Rを使ってGLMMのパラメーターを推定する。
library(glmmML)
glmmML(cbind(y, N-y)~x, data=d, family=binomial)
glmmML(cbind(y, N-y)~x, data=d, family=binomial,+cluster = id)
glmmML(cbind(y, N-y)~x, data=d, family=binomial,cluster = id)
glmmML(cbind(y, N-y)~x, data=d, family=binomial, cluster=id)
fit = glmmML(cbind(y, N-y)~x, data=d, family=binomial, cluster=id)
summary(fit)
# 結果をプロットしてみる
logistic_glmm <- function(x) 1 / (1 + exp(- (-4.190 + 1.005 * x)))
x <- seq(2 ,6, 0.1)
plot(jitter(d$x,0.5), d$y)
points(x,logistic_glmm(x)*8, type = "l")
