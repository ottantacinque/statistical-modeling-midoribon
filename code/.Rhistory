ydata<-dataMDRR[,1]
xdata<-dataMDRR[,-c(1)]
ydata
xdata
tData<-t(xdata)
tData2<-na.omit(tData)
omitData<-t(tData2)
csd<-apply(omitData,2,sd)
nzsc<-(csd!=0)
xdata2<-omitData[,nzsc]
csd<-apply(omitData,2,sd)
nzsc<-(csd!=0)
xdata2<-omitData[,nzsc]
source('~/Desktop/JACI20200908_2nd/RprogrammingLectureCourse/Rfdr01.R')
View(xdata2)
View(xdata2)
#-------------------------
nf<-dim(xdata2)[[2]]
ActD<-xdata2[ydata=="Active",]
InAD<-xdata2[ydata=="Inactive",]
#[1] random data --------------------------------------------
#ActD<-matrix(rnorm(nsA*nf),nrow=nsA,ncol=nf)   #"unif" "norm"
#InAD<-matrix(rnorm(nsI*nf),nrow=nsI,ncol=nf)
#dim(InAD)
#dim(ActD)
#------------------------------------------------------------
pv<-as.numeric(nf)
for(k in 1:nf){
act<-as.vector(ActD[,k])
ina<-as.vector(InAD[,k])
pv[k]<-t.test(act,ina,alternative="two.sided",paired=FALSE,var.equal=FALSE)$p.value
}
#--BH
ntest<-length(pv)
length(pv)
res<-0.01
aa<-hist(pv,breaks =seq(0,1,res))
aa<-hist(pv,breaks =seq(0,1,res))
aa<-hist(pv,breaks =seq(0,1,res))
aa<-hist(pv,breaks =seq(0,1,res))
aa<-hist(pv,breaks =seq(0,1,res))
aa<-hist(pv,breaks =seq(0,1,res))
nr<-ntest*res
abline(a=nr,b=0)
nsig<-aa$count[1]
fdr<-nr/(aa$count[1])    #<----- q-value
nsig #<-------
ncorrect<-nsig*(1-fdr)
for(k in 1:nf){
act<-as.vector(ActD[,k])
ina<-as.vector(InAD[,k])
pv[k]<-t.test(act,ina,alternative="two.sided",paired=FALSE,var.equal=FALSE)$p.value
}
#--BH
ntest<-length(pv)
res<-0.01                    #<-----threshold (p)
aa<-hist(pv,breaks =seq(0,1,res))
nr<-ntest*res
abline(a=nr,b=0)
nsig<-aa$count[1]
fdr<-nr/(aa$count[1])    #<----- q-value
nsig #<-------
ncorrect<-nsig*(1-fdr)
View(ActD)
View(dataMDRR)
View(dataMDRR)
niter<-10000
ptvalues<-rep(0,niter)
ptvalues<-rep(0,niter)
niter<-10000
ptvalues<-rep(0,niter)
ns1<-3
ns2<-3
for(i in 1:niter){
dataRN1<-rnorm(ns1,mean=0,sd=1)
dataRN2<-rnorm(ns2,mean=0,sd=1)
ss<-sqrt((var(dataRN1)/ns1+var(dataRN2)/ns2))
t<-(mean(dataRN1)-mean(dataRN2))/ss
c<-var(dataRN1)/ns1/(var(dataRN1)/ns1+var(dataRN2)/ns2)
dfX<-1/(c*c/(ns1-1)+(1-c)*(1-c)/(ns2-1))
ptvalues[i]<-pt(t,df=dfX)
}
sid<-1:niter
#[1] t-distribution
hist(ptvalues,breaks=seq(0,1,0.01))
t<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-4))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[2] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-2))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[3] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-4))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[2] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-2))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[3] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
niter<-10000
ptvalues<-rep(0,niter)
ns1<-3
ns2<-3
for(i in 1:niter){
dataRN1<-rnorm(ns1,mean=0,sd=1)
dataRN2<-rnorm(ns2,mean=0,sd=1)
ss<-sqrt((var(dataRN1)/ns1+var(dataRN2)/ns2))
t<-(mean(dataRN1)-mean(dataRN2))/ss
c<-var(dataRN1)/ns1/(var(dataRN1)/ns1+var(dataRN2)/ns2)
dfX<-1/(c*c/(ns1-1)+(1-c)*(1-c)/(ns2-1))
ptvalues[i]<-pt(t,df=dfX)
}
sid<-1:niter
#[1] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-4))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[2] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-2))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[3] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[1] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-1))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
#[2] t-distribution
st<-sort(t,decreasing=FALSE)
ptvalue<-pt(st,df=(ns1+ns2-2))
hist(ptvalue,breaks=seq(0,1,0.01))
plot(sid,ptvalue,type="l")
niter<-10000
ptvalues<-rep(0,niter)
ns1<-3
ns2<-3
for(i in 1:niter){
dataRN1<-rnorm(ns1,mean=0,sd=1)
dataRN2<-rnorm(ns2,mean=0,sd=1000)
ss<-sqrt((var(dataRN1)/ns1+var(dataRN2)/ns2))
t<-(mean(dataRN1)-mean(dataRN2))/ss
c<-var(dataRN1)/ns1/(var(dataRN1)/ns1+var(dataRN2)/ns2)
dfX<-1/(c*c/(ns1-1)+(1-c)*(1-c)/(ns2-1))
ptvalues[i]<-pt(t,df=dfX)
}
sid<-1:niter
#[1] t-distribution
hist(ptvalues,breaks=seq(0,1,0.01))
#[1]
data12<-c(474,404,467,446,397,397,451,389,357,450,420,426)
#[1]
data12<-c(474,404,467,446,397,397,451,389,357,450,420,426)
days<-c(31,28,31,30,31,30,31,31,30,31,30,31)
data12<-c(474,404,467,446,397,397,451,389,357,450,420,426)
data12<-(474,404,467,446,397,397,451,389,357,450,420,426)
data12<-a(474,404,467,446,397,397,451,389,357,450,420,426)
data12<-c(474,404,467,446,397,397,451,389,357,450,420,426)
m1<-mean(days)
m1<-mean(days)
cDay<-data12/days*m1
names(cDay)<-c(1,2,3,4,5,6,7,8,9,10,11,12)
cDay
barplot(cDay)
p5<-rep(1/12,12)
chisq.test(cDay,p=p5)
chisq.test(cDay)
#[2]
winter2<-c(cDay[c(1:4,10:12)])
summer2<-c(cDay[c(5:9)])
boxplot(winter2,summer2,names=c("winter","summer"))
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="greater")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
t.test(winter2,summer2,var.equal=FALSE,alternative="greater")
t.test(winter2,summer2,var.equal=FALSE,alternative="two.sided")
summer2
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
chisq.test(Obs,p=P)
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
chisq.test(x=experiment,p=theoretical)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
chisq.test(x=experiment,p=theoretical)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
Ndata<-rnorm(1000,mean=5,sd=3)  #Normal random number
Udata<-runif(1000,min=0,max=1)  #Uniform random number
#--Shapiro Wilk test
shapiro.test(Ndata)
#--Shapiro Wilk test
shapiro.test(Ndata)
shapiro.test(Udata)
#--QQ plot --------------
qqplot(qnorm(ppoints(1000)),Ndata)
qqplot(qnorm(ppoints(1000)),Udata)
#--Shapiro Wilk test
shapiro.test(Ndata)
shapiro.test(Udata)
#--QQ plot --------------
qqplot(qnorm(ppoints(1000)),Ndata)
#--ks test --------------
ks.test(Ndata,"pnorm", mean=mean(Ndata),sd(Ndata))
ks.test(Udata,"pnorm", mean=mean(Udata),sd(Udata))
?ks.test
ks.test(Ndata,"punif")
ks.test(Udata,"punif")
#[1]
Obs<-c(90,110,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#[2]
Obs<-c(50,100,100,100)
P<-c(1/4,1/4,1/4,1/4)
chisq.test(Obs,p=P)
#exp
experiment<-c(6022,2001)
theoretical<-c(3/4, 1/4)
chisq.test(x=experiment,p=theoretical)
#Quiz42
#Quiz42
#ア:帰無仮説
#Quiz42
#ア:帰無仮説
#イ:帰無仮説
#データの読み込み
load("data.Rata")
data
length(data)
# dataの要約
summary(data)
# 度数分布を得る
table(data)
# ヒストグラム
hist(data, breaks = seq(-0.5, 9.5, 1))
# 標本分散
var(data)
# 標本標準偏差
sd(data)
sqrt(var(data))
# 平均3.56のポアソン分布を図示してみる。
y <- 0:9
prob <- dpois(y, lambda = 3.56)
plot(y, prob, type = "b", lty = 2)
# 対数尤度LogL(lambda)とlambdaの関係を調べる
logL <- function(m) sum(dpois(data, m, log=TRUE))
y <- 0:9
prob <- dpois(y, lambda = 3.56)
plot(y, prob, type = "b", lty = 2)
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "b", lty = 2)
# 平均3.56のポアソン分布を図示してみる。
y <- 0:9
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "b", lty = 2)
plot(y, prob, type = "l", lty = 2)
plot(y, prob, type = "l", lty = 3)
#データの読み込み
load("data.Rata")
ls
cd
ls
#データの読み込み
load("data.Rata")
data
length(data)
data
length(data)
#データの読み込み
load("data.Rata")
data
length(data)
#データの読み込み
load("data.Rata")
data
length(data)
load("~/Desktop/統計モデリング/.RData")
View(d)
# dataの要約
summary(data)
# 度数分布を得る
table(data)
# ヒストグラム
hist(data, breaks = seq(-0.5, 9.5, 1))
# 標本分散
var(data)
# 標本標準偏差
sd(data)
sqrt(var(data))
# 平均3.56のポアソン分布を図示してみる。
y <- 0:9
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "l", lty = 3)
# 対数尤度LogL(lambda)とlambdaの関係を調べる
logL <- function(m) sum(dpois(data, m, log=TRUE))
lambda <- seq(2, 5, 0.1)
plot(lambda, sapply(lambda, logL), type= "l")
View(d)
data <- c(2, 4, 6, 4, 5, 2, 3, 1, 2, 0,
4, 3, 3, 3, 3, 4, 2, 7, 2, 4,
3, 3, 3, 4, 3, 7, 5, 3, 1, 7,
6, 4, 6, 5, 2, 4, 7, 2, 2, 6,
2, 4, 5, 4, 5, 1, 3, 2, 3)
data
length(data)
# dataの要約
summary(data)
# 度数分布を得る
table(data)
y <- 0:9
prob <- dpois(y, lambda = 3)
plot(y, prob, type = "b", lty = 3)
y <- 0:9
prob <- dpois(y, lambda = 6)
plot(y, prob, type = "b", lty = 3)
logL <- function(m) sum(dpois(data, m, log=TRUE))
lambda <- seq(2, 5, 0.1)
plot(lambda, sapply(lambda, logL), type= "l")
#データの読み込み
load("data.Rata")
data <- read.csv("./../data/my_data.csv")
data <- read.csv("./../data/data.csv")
data <- read.csv("/../data/data.csv")
getwd()
getwd()
cd()
cd
ls
#データの読み込み
getwd()
#データの読み込み
getwd()
data <- read.csv("/../data/data.csv")
F1<-100
F2<-4
N<-10000
FV1<-rchisq(N,df=F1)/F1
FV2<-rchisq(N,df=F2)/F2
Frand<-FV1/FV2
ff<-Frand[Frand<10]
#[1]
hist(ff,breaks=seq(0,10,0.1),freq=FALSE)
curve(df(x,df1=F1,df2=F2),from=0,to=10,add=T,col="red")
#[2]
prob<-pf(ff,df1=F1,df2=F2)
hist(prob,breaks=seq(0,1,0.05))
#[1]
hist(ff,breaks=seq(0,10,0.1),freq=FALSE)
curve(df(x,df1=F1,df2=F2),from=0,to=10,add=T,col="red")
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
head(df)
labeldata<-substring(rownames(df),1,2)
#---------------------------------------------------------
#df<-scale(df)
dataNew<-data.frame(labeldata,df)
dim(dataNew)
sc<-3    #X variables 2-16
dim(dataNew)
#---------------------------------------------------------
#df<-scale(df)
dataNew<-data.frame(labeldata,df)
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
ifname <- "DataBrandy.csv"
df <- read.delim(ifname, header=T,sep=",",row.names=1,as.is=TRUE,strip.white=FALSE)
exdata<-c(210,417,136,131,30,435,91,129,
49, 35, 26,  9,26, 12, 9,  7,
96, 85, 42, 22,15, 23,21, 43)
grp<-c("G","G","G","G","G","G","G","G",
"C","C","C","C","C","C","C","C",
"F","F","F","F", "F","F","F","F")
summary(aov(exdata~grp))
#boxplot
grpdata<-tapply(exdata,grp,list)
boxplot(grpdata)
summary(aov(exdata~grp))
grpvar <- tapply(exdata,grp,var)
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
1-pf(Fdata,df1=2,df2=21)
#========================================
summary(aov(exdata~grp))
grpvar <- tapply(exdata,grp,var)
VE <- sum(grapvar * 8) / 21
#========================================
summary(aov(exdata~grp))
grpvar <- tapply(exdata,grp,var)
VE <- sum(grpvar * 8) / 21
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
VA <-  8 * sum((grpmean-allmean)^2) / 2
# fvalue
Fdata = VA/VE
1-pf(Fdata,df1=2,df2=21)
summary(aov(exdata~grp))
1-pf(Fdata,df1=2,df2=21)
# fvalue
VA/VE
1-pf(Fdata,df1=2,df2=21)
VA <-  21 * sum((grpmean-allmean)^2) / 2
# fvalue
VA/VE
1-pf(Fdata,df1=2,df2=21)
VE <- sum(grpvar * 7) / 21
grpmean <- tapply(exdata, grp, mean)
allmean <- mean(exdata)
VA <-  8 * sum((grpmean-allmean)^2) / 2
# fvalue
VA/VE
1-pf(Fdata,df1=2,df2=21)
# fvalue
Fdata = VA/VE
1-pf(Fdata,df1=2,df2=21)
d <- read.csv("data7.csv")
summary(d)
# プロットの作成
plot(jitter(d$x,0.5), d$y)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-2.1487 + 0.5104 * x)))
x <- seq(2 ,6, 0.1)
plot(jitter(d$x,0.5), d$y)
points(x,logistic(x)*8, type = "l")
# 7.1 例題；GLMでは説明出来ないカウントデータ
d <- read.csv("data7.csv")
summary(d)
# プロットの作成
plot(jitter(d$x,0.5), d$y)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-2.1487 + 0.5104 * x)))
x <- seq(2 ,6, 0.1)
plot(jitter(d$x,0.5), d$y)
plot(jitter(d$x,0.5), d$y)
points(x,logistic(x)*8, type = "l")
summary(d)
# 7.1 例題；GLMでは説明出来ないカウントデータ
d <- read.csv("data7.csv")
setwd("~/Desktop/statistical-modeling-midoribon/code")
# 7.1 例題；GLMでは説明出来ないカウントデータ
d <- read.csv("data7.csv")
summary(d)
# プロットの作成
plot(jitter(d$x,0.5), d$y)
# GLMを当てはめてみる。
fit <- glm(cbind(y, N - y) ~ x, data = d, family = binomial)
summary(fit)
# 結果をプロットしてみる
logistic <- function(x) 1 / (1 + exp(- (-2.1487 + 0.5104 * x)))
x <- seq(2 ,6, 0.1)
plot(jitter(d$x,0.5), d$y)
points(x,logistic(x)*8, type = "l")
