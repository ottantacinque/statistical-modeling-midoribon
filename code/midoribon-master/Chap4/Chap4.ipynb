{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GLMのモデル選択"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. モデル選択とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. \n",
    "* 良い予測をするモデルを探すこと\n",
    "* 「当てはまりのよさ」だけで選んではいけない\n",
    "    * 複雑な統計モデルほど、観測データへの当てはまりは良くなる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. AICとは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "* 「良い予測をするモデルが良いモデルである」という考えに基づいて設計された、モデル選択基準\n",
    "* 「当てはまりの良さ重視」とは異なる考え方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. データはひとつ、モデルはたくさん"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 第3章では、同じデータについて、いくつかの統計モデルで説明した\n",
    "* 統計モデルのパラメータを最尤推定する際には、対数尤度が「いま手元にある観測データへの当てはまりの良さ」であると考え、これを最大にするようなパラメータの値を探した\n",
    "* では、最大対数尤度こそがモデルの良さであると考えれば良いのだろうか？\n",
    "* ->そうではない、というのが本章の要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. 統計モデルのあてはまりの悪さ：逸脱度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 逸脱度とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "* あてはまりの良さである最大対数尤度を変形した統計量\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ある対数尤度$ \\log L( \\{ \\beta_j \\} )$を$\\log L$ と表記する\n",
    "* この$\\log L$を最大にするパラメータを探すのが最尤推定法\n",
    "* 最大対数尤度を $\\log L^*$と表記する\n",
    "\n",
    "\n",
    "とした時、逸脱度の定義式は？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. \n",
    "$$\n",
    "D = -2\\log L^*\n",
    "$$\n",
    "* 「あてはまりの良さ」ではなく「あてはまりの悪さ」を表現する指標\n",
    "* 数値が大きいほど、あてはまりが悪い\n",
    "* 最大対数尤度$\\log L^*$に$-2$をかけている\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 残差逸脱度とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "* $D -$(ポアソン分布モデルで可能な最小逸脱度）\n",
    "* この最小逸脱度をフルモデルと呼び、データ数と同じだけのパラメータを使って当てはめたモデル\n",
    "* つまり残差逸脱度は、もっともあてはまりの良いフルモデルを基準とする「あてはまりの悪さ」の相対値。\n",
    "* 残差逸脱度が最大になるのは、「もっともあてはまりの悪いモデル」の場合\n",
    "* ポアソン分布だとこれは、もっともパラメーター数の少ないモデル null modelである。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 体サイズ$x_i$だけに依存するモデルで計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data3a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takizawa/dev/python/books/midori/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = smf.glm('y ~ x',data=data,family=sm.families.Poisson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>y</td>        <th>  No. Observations:  </th>  <td>   100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    98</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -235.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Thu, 06 Jul 2017</td> <th>  Deviance:          </th> <td>  84.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>00:48:26</td>     <th>  Pearson chi2:      </th>  <td>  83.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>4</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.2917</td> <td>    0.364</td> <td>    3.552</td> <td> 0.000</td> <td>    0.579</td> <td>    2.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.0757</td> <td>    0.036</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.145</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  100\n",
       "Model:                            GLM   Df Residuals:                       98\n",
       "Model Family:                 Poisson   Df Model:                            1\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -235.39\n",
       "Date:                Thu, 06 Jul 2017   Deviance:                       84.993\n",
       "Time:                        00:48:26   Pearson chi2:                     83.8\n",
       "No. Iterations:                     4                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.2917      0.364      3.552      0.000       0.579       2.005\n",
       "x              0.0757      0.036      2.125      0.034       0.006       0.145\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pythonだと、Deviance 84.993と表示されている。おそらくResidual Deviance\n",
    "* Null Devianceは表示されない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full modelの逸脱度の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100個のdata.yに対し、100個のパラメータを用いて当てはめることを考える。\n",
    "* ポアソン回帰で可能な他のどのモデルよりも「当てはまりの良さ」である対数尤度は大きくなる。\n",
    "* ある1つのデータに対し、そのデータの値を平均とした、ポアソン分布の（最大）対数尤度を取得するlambda式 dpois を定義。\n",
    "* data.yの1つずつに対し、dpoisを当てはめ計算。\n",
    "* それらを足し合わせてfull modelの最大対数尤度を計算。\n",
    "* $-2$を掛け算し、最小逸脱度を求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpois = lambda x:scs.poisson.logpmf(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      6\n",
       "3     12\n",
       "4     10\n",
       "5      4\n",
       "6      9\n",
       "7      9\n",
       "8      9\n",
       "9     11\n",
       "10     6\n",
       "11    10\n",
       "12     6\n",
       "13    10\n",
       "14    11\n",
       "15     8\n",
       "16     3\n",
       "17     8\n",
       "18     5\n",
       "19     5\n",
       "20     4\n",
       "21    11\n",
       "22     5\n",
       "23    10\n",
       "24     6\n",
       "25     6\n",
       "26     7\n",
       "27     9\n",
       "28     3\n",
       "29    10\n",
       "      ..\n",
       "70    10\n",
       "71     8\n",
       "72     8\n",
       "73     7\n",
       "74     5\n",
       "75     6\n",
       "76     8\n",
       "77     9\n",
       "78     9\n",
       "79     6\n",
       "80     7\n",
       "81    10\n",
       "82     6\n",
       "83    11\n",
       "84    11\n",
       "85    11\n",
       "86     5\n",
       "87     6\n",
       "88     4\n",
       "89     5\n",
       "90     6\n",
       "91     5\n",
       "92     8\n",
       "93     5\n",
       "94     9\n",
       "95     8\n",
       "96     6\n",
       "97     8\n",
       "98     7\n",
       "99     9\n",
       "Name: y, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8286944 , -1.8286944 , -1.8286944 , -2.1683347 , -2.07856164,\n",
       "       -1.63287639, -2.02680628, -2.02680628, -2.02680628, -2.12545985,\n",
       "       -1.8286944 , -2.07856164, -1.8286944 , -2.07856164, -2.12545985,\n",
       "       -1.96907057, -1.4959226 , -1.96907057, -1.74030218, -1.74030218,\n",
       "       -1.63287639, -2.12545985, -1.74030218, -2.07856164, -1.8286944 ,\n",
       "       -1.8286944 , -1.90379032, -2.02680628, -1.4959226 , -2.07856164,\n",
       "       -1.30685282, -2.02680628, -2.07856164, -1.74030218, -2.12545985,\n",
       "       -2.07856164, -1.63287639, -1.96907057, -2.02680628, -2.1683347 ,\n",
       "       -1.96907057, -2.02680628, -1.96907057, -1.8286944 , -1.8286944 ,\n",
       "       -2.07856164, -2.07856164, -2.02680628, -2.1683347 , -1.8286944 ,\n",
       "       -2.24441857, -1.8286944 , -1.90379032, -2.02680628, -1.8286944 ,\n",
       "       -1.90379032, -2.02680628, -2.20782221, -2.02680628, -2.20782221,\n",
       "       -1.90379032, -1.96907057, -2.07856164, -1.90379032, -2.1683347 ,\n",
       "       -1.8286944 , -2.27851837, -1.4959226 , -1.63287639, -1.8286944 ,\n",
       "       -2.07856164, -1.96907057, -1.96907057, -1.90379032, -1.74030218,\n",
       "       -1.8286944 , -1.96907057, -2.02680628, -2.02680628, -1.8286944 ,\n",
       "       -1.90379032, -2.07856164, -1.8286944 , -2.12545985, -2.12545985,\n",
       "       -2.12545985, -1.74030218, -1.8286944 , -1.63287639, -1.74030218,\n",
       "       -1.8286944 , -1.74030218, -1.96907057, -1.74030218, -2.02680628,\n",
       "       -1.96907057, -1.8286944 , -1.96907057, -1.90379032, -2.02680628])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpois(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-192.8897525244958"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_logl = sum(dpois(data.y))\n",
    "max_logl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385.77950504899161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_dev = sum(dpois(data.y)) * -2\n",
    "min_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最小逸脱度は385程度となった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### null modelの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ポアソン回帰ではもっともパラメータ数の少ないモデル。切片 $\\beta_1$だけのモデル（パラメータ数$k=1$）\n",
    "* 一定モデルとも呼ばれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = smf.glm('y ~ 1',data=data,family=sm.families.Poisson())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>y</td>        <th>  No. Observations:  </th>  <td>   100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    99</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -237.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Thu, 06 Jul 2017</td> <th>  Deviance:          </th> <td>  89.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>00:48:26</td>     <th>  Pearson chi2:      </th>  <td>  87.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>4</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.0580</td> <td>    0.036</td> <td>   57.586</td> <td> 0.000</td> <td>    1.988</td> <td>    2.128</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  100\n",
       "Model:                            GLM   Df Residuals:                       99\n",
       "Model Family:                 Poisson   Df Model:                            0\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -237.64\n",
       "Date:                Thu, 06 Jul 2017   Deviance:                       89.507\n",
       "Time:                        00:48:26   Pearson chi2:                     87.1\n",
       "No. Iterations:                     4                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.0580      0.036     57.586      0.000       1.988       2.128\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Devianceは89.507とResidualDevianceと一致している\n",
    "* 一定モデルの最大対数尤度は-237.64となっており、逸脱度は475程度、最小逸脱度との差は475-385=90となり、Devianceと一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (復習)一定モデルなら $\\lambda$ はデータの平均と一致\n",
    "* $\\log \\lambda = \\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8300000000000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0579625100027119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(data.y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. モデル選択基準 AIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* パラメータ数の多い統計モデルほど、データへのあてはまりが良くなる\n",
    "* しかしそれは「たまたま得られたデータへの当てはめ向上を目的とする特殊化」であり、統計モデルの「予測の良さ」を損なっているのかもしれない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. モデル選択とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "* 複数の統計モデルの中から、何らかの基準で良いモデルを選択すること\n",
    "* よく使われているモデル選択基準の1つがAIC(Akaike's information criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. AICとは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "* 予測の良さを重視するモデル選択基準\n",
    "* $AIC = -2 \\{ $ ( 最大対数尤度 ) - (最尤推定したパラメータ数)$\\}$ \n",
    "$$= -2(\\log L^* - k) $$\n",
    "$$= D + 2k$$\n",
    "* このAICが一番小さいモデルが良いモデルとなる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. AICを説明するためのまた別の問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* AICがなぜ統計モデルの予測力を表しているのか考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. ネストしているモデルとは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "\n",
    "* 一定モデル($\\log \\lambda_i = \\beta_1$) と xモデル（$\\log \\lambda_i = \\beta_1 + \\beta_2 x_i$）のように、一方のモデルに他方が含まれているようなくみあわせ。（$\\beta_2 = 0$とすれば、xモデルは一定モデルと同様になる）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. なぜAICでモデル選択して良いのか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1. 統計モデルの予測の良さ：平均対数尤度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 平均対数尤度$E(\\log L)$は統計モデルの予測の良さを表す量\n",
    "* 真の統計モデルに基づくデータセットに対し、すでに推定されたモデルの当てはまりの良さを対数尤度で評価し、その平均をとったもの"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 統計モデルのパラメータ推定の概念\n",
    "* 人間には見えない真の統計モデルがある\n",
    "* それを元に、観測データがサンプリングされる\n",
    "* 観測データを元にパラメータ推定する\n",
    "* そのため、パラメータ推定によって求められたパラメータと最大対数尤度は、たまたま得られた観測データ自身に対する当てはまりの良さであり、真の統計モデルに似ているかは考慮されない\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. データ解析の狙いは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. \n",
    "* 観測される現象の背後にある「仕組み」の特定、もしくはそれを近似的に代替しうる統計モデルの構築\n",
    "* そのため、「たまたま得られた」観測データへの当てはまりの良さを追求してはならない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 推定された統計モデルが真の統計モデルにどれぐらい近いのかを調べる方法は？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. \n",
    "* 真の統計モデルがわかっているのなら、そこから「予測の良さ評価用のデータ」を生成し、推定された一定モデルのどの程度当てはまるのか調べる\n",
    "* 教科書の喩えだと、50個のサンプルを200セット作成。\n",
    "* 各セットに対して対数尤度で評価する。その200の結果の平均を、平均対数尤度と呼ぶ。\n",
    "* しかし、真の統計モデルがわかってることなどほぼない（わかってたら観測しない）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2. 最大対数尤度のバイアス補正\n",
    "* たまたま得られた観測データで推定されたモデルでは、当てはまりの良さが過大評価される（常に過大評価される訳ではない）\n",
    "* 平均対数尤度の作成を12回繰り返す。すると、最大対数尤度（観測データへの当てはまり）と平均対数尤度（真の統計モデルから生成したデータへの当てはまり）は必ずしもどちらが良いとは言えないことがわかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. バイアスとは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. \n",
    "* $ b = \\log L^* - E(\\log L) $\n",
    "* 「推定用データ生成、パラメータ推定、予測の良さを評価」を200回繰り返し、バイアスbの分布を描くことで、平均対数尤度より、最大対数尤度の方が平均的にどれぐらい大きいか(平均バイアス)、ということがわかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. バイアス補正とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "* 平均的な$b$と最大対数尤度$\\log L^*$の値を元に下記の計算式で平均対数尤度の推定量を得ること\n",
    "* $E(\\log L) = \\log L^* - b$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 最尤推定するパラメータを$k$個持つモデルの平均対数尤度の推定量を求める式は？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.\n",
    "* $E(\\log L) = \\log L^* - k$（解析的かつ一般的に導出されているらしい）\n",
    "* 上記に$-2$をかけたものが$AIC$。\n",
    "* $AIC = -2 \\times (\\log L^* -k)$\n",
    "* 平均対数尤度は「統計モデルの予測の良さ」であり、それに $-2$をかけた$AIC$は「予測の悪さ」と解釈できる。AICが低いモデルを選べば良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3. ネストしているGLM間のAIC比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AICによるモデル選択とは、複数のモデルのAICを比較してより小さいAICのモデルを選ぶこと\n",
    "* バイアスのばらつきは大きいため、AICで評価して良いか不安になる。しかし同一データを使ってネストしている複数モデルのバイアス補正量のさの分布はそれほどばらつきの大きいものにはならないため、AICは有用である。\n",
    "* ではネストしていない複数のモデルで、AICによるモデル選択は可能だろうか。現時点では、「多分問題ないだろう」という理由で用いられている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. この章のまとめと参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 「当てはまりの良さ」最大対数尤度 $\\log L^*$で「良い」モデルを選んではいけない。\n",
    "* 「当てはまりの悪さ」逸脱度 $ D = -2 \\log L^*$\n",
    "* モデルは複雑化するだけで、最大対数尤度 $\\log L^*$は改善されてしまう。そのためモデルの複雑さを考慮したAICでモデル選択しなければならない。\n",
    "* AICは平均対数尤度の推定値。これは最大対数尤度 $\\log L^*$のバイアス補正によって評価される。\n",
    "* AICは当てはまりの良いモデルではなく、良い予測をするモデルを選ぶ基準。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AICによるモデル選択における注意点\n",
    "* モデル選択の目的は「真の」モデルを求めることではない\n",
    "* データ数が少ない場合には、「真の」モデルより、単純なモデルの方が予測能力が高い可能性もある\n",
    "* データ数が少ない場合には、選択されたパラメータ数が過大であっても、「余計な」パラメータの推定地はゼロに近づくので問題ない\n",
    "* モデル選択は、データ解析者が用意したモデルたちの中から良いモデルを選んでいるので、よりAICが良いモデルが他に存在する可能性がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* その他のモデル選択基準としては、交差検証法、ブートストラップ情報量基準など。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 表4.3の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_list = [\"y ~ 1\",\"y ~ f\",\"y ~ x\",\"y ~ x + f\"]\n",
    "k_list = list()\n",
    "logl_list = list()\n",
    "deviance_2logl_list = list()\n",
    "residual_deviance_list = list()\n",
    "aic_list = list()\n",
    "\n",
    "for model_str in model_list:\n",
    "    model = smf.glm(model_str,data=data,family=sm.families.Poisson())\n",
    "    result = model.fit()\n",
    "    result.summary()\n",
    "    \n",
    "    k = result.df_model+1\n",
    "    k_list.append(k)\n",
    "    \n",
    "    logl = result.llf\n",
    "    logl_list.append(logl)\n",
    "\n",
    "    deviance_2logl = - 2*logl\n",
    "    deviance_2logl_list.append(deviance_2logl)\n",
    "    \n",
    "    residual_deviance = result.deviance\n",
    "    residual_deviance_list.append(residual_deviance)\n",
    "\n",
    "\n",
    "\n",
    "    aic = -2*(logl-k)\n",
    "    aic_list.append(aic)\n",
    "\n",
    "    \n",
    "# fullmodelのデータを追加する\n",
    "# 一部の数値は上で計算している\n",
    "model_list.append(\"full model\")\n",
    "k_list.append(100)\n",
    "logl_list.append(max_logl)\n",
    "deviance_2logl_list.append(min_dev)\n",
    "residual_deviance_list.append(0)\n",
    "aic_list.append(-2*(max_logl-100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_aic = pd.DataFrame(index=model_list)\n",
    "df_aic[\"k\"] = k_list\n",
    "df_aic[\"logl\"] = logl_list\n",
    "df_aic[\"deviance_2logl\"] = deviance_2logl_list # \n",
    "df_aic[\"residual_deviance\"] = residual_deviance_list #残差逸脱度\n",
    "df_aic[\"aic\"] = aic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>logl</th>\n",
       "      <th>deviance_2logl</th>\n",
       "      <th>residual_deviance</th>\n",
       "      <th>aic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y ~ 1</th>\n",
       "      <td>1</td>\n",
       "      <td>-237.643221</td>\n",
       "      <td>475.286443</td>\n",
       "      <td>89.506938</td>\n",
       "      <td>477.286443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y ~ f</th>\n",
       "      <td>2</td>\n",
       "      <td>-237.627257</td>\n",
       "      <td>475.254514</td>\n",
       "      <td>89.475009</td>\n",
       "      <td>479.254514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y ~ x</th>\n",
       "      <td>2</td>\n",
       "      <td>-235.386251</td>\n",
       "      <td>470.772502</td>\n",
       "      <td>84.992996</td>\n",
       "      <td>474.772502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y ~ x + f</th>\n",
       "      <td>3</td>\n",
       "      <td>-235.293719</td>\n",
       "      <td>470.587438</td>\n",
       "      <td>84.807933</td>\n",
       "      <td>476.587438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full model</th>\n",
       "      <td>100</td>\n",
       "      <td>-192.889753</td>\n",
       "      <td>385.779505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>585.779505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              k        logl  deviance_2logl  residual_deviance         aic\n",
       "y ~ 1         1 -237.643221      475.286443          89.506938  477.286443\n",
       "y ~ f         2 -237.627257      475.254514          89.475009  479.254514\n",
       "y ~ x         2 -235.386251      470.772502          84.992996  474.772502\n",
       "y ~ x + f     3 -235.293719      470.587438          84.807933  476.587438\n",
       "full model  100 -192.889753      385.779505           0.000000  585.779505"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* aicは低いものを選べば良いので、\"y ~ x\"のモデルを選ぶと良い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 同様に、ポアソン回帰ではなく線形回帰で実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>logl</th>\n",
       "      <th>deviance_2logl</th>\n",
       "      <th>residual_deviance</th>\n",
       "      <th>aic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y ~ 1</th>\n",
       "      <td>1</td>\n",
       "      <td>-237.894891</td>\n",
       "      <td>475.789782</td>\n",
       "      <td>682.110000</td>\n",
       "      <td>477.789782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y ~ f</th>\n",
       "      <td>2</td>\n",
       "      <td>-237.876562</td>\n",
       "      <td>475.753124</td>\n",
       "      <td>681.860000</td>\n",
       "      <td>479.753124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y ~ x</th>\n",
       "      <td>2</td>\n",
       "      <td>-235.233125</td>\n",
       "      <td>470.466250</td>\n",
       "      <td>646.747281</td>\n",
       "      <td>474.466250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y ~ x + f</th>\n",
       "      <td>3</td>\n",
       "      <td>-235.118314</td>\n",
       "      <td>470.236628</td>\n",
       "      <td>645.263913</td>\n",
       "      <td>476.236628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           k        logl  deviance_2logl  residual_deviance         aic\n",
       "y ~ 1      1 -237.894891      475.789782         682.110000  477.789782\n",
       "y ~ f      2 -237.876562      475.753124         681.860000  479.753124\n",
       "y ~ x      2 -235.233125      470.466250         646.747281  474.466250\n",
       "y ~ x + f  3 -235.118314      470.236628         645.263913  476.236628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = [\"y ~ 1\",\"y ~ f\",\"y ~ x\",\"y ~ x + f\"]\n",
    "k_list = list()\n",
    "logl_list = list()\n",
    "deviance_2logl_list = list()\n",
    "residual_deviance_list = list()\n",
    "aic_list = list()\n",
    "\n",
    "for model_str in model_list:\n",
    "    # 線形回帰\n",
    "    model = smf.glm(model_str,data=data)\n",
    "    result = model.fit()\n",
    "    result.summary()\n",
    "    \n",
    "    k = result.df_model+1\n",
    "    k_list.append(k)\n",
    "    \n",
    "    logl = result.llf\n",
    "    logl_list.append(logl)\n",
    "    \n",
    "    deviance_2logl = - 2*logl\n",
    "    deviance_2logl_list.append(deviance_2logl)\n",
    "    \n",
    "    residual_deviance = result.deviance\n",
    "    residual_deviance_list.append(residual_deviance)\n",
    "\n",
    "\n",
    "    aic = -2*(logl-k)\n",
    "    aic_list.append(aic)\n",
    "\n",
    "    \n",
    "df_aic = pd.DataFrame(index=model_list)\n",
    "df_aic[\"k\"] = k_list\n",
    "df_aic[\"logl\"] = logl_list\n",
    "df_aic[\"deviance_2logl\"] = deviance_2logl_list\n",
    "df_aic[\"residual_deviance\"] = residual_deviance_list\n",
    "df_aic[\"aic\"] = aic_list\n",
    "\n",
    "df_aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 上記の結果をどう判断すべきか\n",
    "* AICでみると、『線形回帰の「y ~ x」』がもっとも低い。\n",
    "* しかし、線形回帰は正規分布を前提とし、範囲が±∞となることから、定性的には正しくないように思える。\n",
    "* このような時、どれを用いれば良いか。\n",
    "* 学習結果を見てみると、「P>|z|」が0.05　以上となっていることが多かった。\n",
    "    * P値？\n",
    "    \n",
    "* （勉強会で頂いたコメント）確率分布が違うとき、AICで比較してはいけないようだ。\n",
    "    * [久保先生の資料](http://hosho.ees.hokudai.ac.jp/~kubo/ce/FaqModelSelection.html#toc14)によると、下記。\n",
    "        * 離散分布 vs 連続分布の場合はダメ\n",
    "            * 理由: 対数尤度の計算方法が離散分布と連続分布で異なるため …… それ以前の問題として，そもそもある観測データに対してこういう比較をすること自体がまったくナンセンスなんですけど"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>y</td>        <th>  No. Observations:  </th>    <td>   100</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>    <td>    98</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>       <td>Gaussian</td>     <th>  Df Model:          </th>    <td>     1</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>      <td>identity</td>     <th>  Scale:             </th> <td>6.59946204749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th>   <td> -235.23</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Thu, 06 Jul 2017</td> <th>  Deviance:          </th>   <td>  646.75</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>00:48:26</td>     <th>  Pearson chi2:      </th>    <td>  647.</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>2</td>        <th>                     </th>       <td> </td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.8483</td> <td>    2.597</td> <td>    0.712</td> <td> 0.477</td> <td>   -3.241</td> <td>    6.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.5929</td> <td>    0.256</td> <td>    2.315</td> <td> 0.021</td> <td>    0.091</td> <td>    1.095</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  100\n",
       "Model:                            GLM   Df Residuals:                       98\n",
       "Model Family:                Gaussian   Df Model:                            1\n",
       "Link Function:               identity   Scale:                   6.59946204749\n",
       "Method:                          IRLS   Log-Likelihood:                -235.23\n",
       "Date:                Thu, 06 Jul 2017   Deviance:                       646.75\n",
       "Time:                        00:48:26   Pearson chi2:                     647.\n",
       "No. Iterations:                     2                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.8483      2.597      0.712      0.477      -3.241       6.938\n",
       "x              0.5929      0.256      2.315      0.021       0.091       1.095\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.glm(\"y ~ x\",data=data)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰のフルモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 線形回帰の場合、確率はどのように求める？線形回帰の場合は連続値を取るため、ある値を取ることの確率が求められない。\n",
    "* 何らかの形で範囲を決める必要？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# キーワードまとめ\n",
    "| 名称| 説明 | 式 |\n",
    "|:-----------:|:------------:|:------------:|\n",
    "| 対数尤度       | 当てはまりの良さ| $\\log L$ |\n",
    "| 最大対数尤度 | もっとも当てはまりの良いパラメータで計算した対数尤度 | $\\log L^*$ |\n",
    "| 逸脱度 | 当てはまりの悪さ | $D = -2 \\log L$ |\n",
    "| 残差逸脱度 | 当てはまりの悪さの相対値 | $D-$(当該分布モデルで可能な最小逸脱度) |\n",
    "| 平均対数尤度| 統計モデルの「予測」の良さ | $E(\\log L)$ |\n",
    "| バイアス| 最大対数尤度と平均対数尤度の差 | $b = \\log L^* - E(\\log L)$ |\n",
    "| AIC| 統計モデルの予測の悪さ | $AIC = -2 \\times (\\log L^* - k) $|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
